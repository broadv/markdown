#### 添加软件源
```
$vim /etc/apt/source.list
deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted
deb http://mirrors.aliyun.com/ubuntu/ xenial universe
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe
deb http://mirrors.aliyun.com/ubuntu/ xenial multiverse
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiverse
deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu xenial-security main restricted
deb http://mirrors.aliyun.com/ubuntu xenial-security universe
deb http://mirrors.aliyun.com/ubuntu xenial-security multiverse
```

### 安装必要的软件
```
apt-get install -y conntrack ipvsadm ntp ipset jq iptables curl sysstat libseccomp2 ntpdate && modprobe ip_vs
```

#### 关闭 swap
```
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```
#### 内核参数调整
```
cat > cephsysctl.conf <<EOF
#net.ipv4.ip_forward = 1
vm.swappiness = 0
vm.overcommit_memory = 1
vm.panic_on_oom = 0
fs.inotify.max_user_instances = 8192
fs.inotify.max_user_watches = 1048576
fs.file-max = 52706963
fs.nr_open = 52706963
net.ipv6.conf.all.disable_ipv6 = 1
EOF
cp cephsysctl.conf /etc/sysctl.d/cephsysctl.conf
sysctl -p /etc/sysctl.d/cephsysctl.conf
```
#### 升级 kernel
```

```
#### 设置时区
```
# 调整系统 TimeZone
timedatectl set-timezone Asia/Shanghai

# 将当前的 UTC 时间写入硬件时钟
timedatectl set-local-rtc 0

# 重启依赖于系统时间的服务
systemctl restart rsyslog 
```

#### 关闭防火墙，设置 iptables 转发规则
```
systemctl stop ufw
systemctl disable ufw
iptables -F && iptables -X && iptables -F -t nat && iptables -X -t nat
iptables -P FORWARD ACCEPT
```

#### 更新ceph安装源[每个安装节点]
```bash
wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add -
echo deb https://mirrors.aliyun.com/ceph/debian-nautilus/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list
apt-get update
#安装python2
apt-get install python
apt-get install ceph-deploy
```

#### admin安装ceph-deploy
```
&ceph-deploy
```

#### 在节点安装ceph组件
```bash
ceph-deploy install --no-adjust-repos $admin  #admin节点，即用于部署的节点
ceph-deploy install --no-adjust-repos $node1
```

### 创建一个新的ceph集群
```bash
mkdir -p ceph & cd ceph
ceph-deploy new $node1 $node2 $node3 $node4 $node5
ceph-deploy --overwrite-conf mon create-initial
```

#### push配置信息
```bash
ceph-deploy --overwrite-conf admin $admin
ceph-deploy --overwrite-conf config push $node
```
#### 检查mon
```bash
ceph quorum_status --format json-pretty
ceph --cluster=ceph mon stat --format=json
```
#### 配置服务
```bash
ceph-deploy --overwrite-conf  mgr create $node
ceph-deploy --overwrite-conf  mon create $node
ceph-deploy --overwrite-conf  mds create $node
```
#### 添加OSD
```bash
ceph auth get client.bootstrap-osd -o /var/lib/ceph/bootstrap-osd/ceph.keyring
ceph-volume lvm create --bluestore --data /dev/sdy --block.wal /dev/nvme1n1p1 --block.db /dev/nvme0n1p1
```

#### 创建规则
+ 创建虚拟根
```bash
ceph osd crush add-bucket root-meta root
ceph osd crush add-bucket root-data root
ceph osd crush add-bucket root-tier root
```
+ 创建虚拟主机
```bash
## 元素据
ceph osd crush add-bucket host-vir-meta1 host
ceph osd crush add-bucket host-vir-meta2 host
ceph osd crush add-bucket host-vir-meta3 host
ceph osd crush add-bucket host-vir-meta4 host

# 读SSD加速盘
ceph osd crush add-bucket host-vir-tier1 host
ceph osd crush add-bucket host-vir-tier2 host
ceph osd crush add-bucket host-vir-tier3 host
ceph osd crush add-bucket host-vir-tier4 host
```

+ 创建规则集
```bash
ceph osd crush rule create-simple rule-meta  root-meta host
ceph osd crush rule create-simple rule-data  root-data host
ceph osd crush rule create-simple rule-tier  root-tier host
```

+ 移动虚拟主机及主机对OSD进行分类
```bash
# 数据池
ceph osd crush move ceph-tal-osd1 root=root-data
ceph osd crush move ceph-tal-osd2 root=root-data
ceph osd crush move ceph-tal-osd3 root=root-data
ceph osd crush move ceph-tal-osd4 root=root-data
ceph osd crush move ceph-tal-osd5 root=root-data
ceph osd crush move ceph-tal-osd6 root=root-data
ceph osd crush move ceph-tal-osd7 root=root-data
# 元数据池
ceph osd crush move host-vir-meta1 root=root-meta
ceph osd crush move host-tal-meta2 root=root-meta
ceph osd crush move host-tal-meta3 root=root-meta
#移动OSD到meta的虚拟主机
ceph osd crush move osd.0 host=host-vir-meta1

ceph osd crush move osd.1 host=host-tal-meta1
ceph osd crush move osd.4 host=host-tal-meta2
ceph osd crush move osd.5 host=host-tal-meta2
ceph osd crush move osd.8 host=host-tal-meta3
ceph osd crush move osd.9 host=host-tal-meta3
```
+ 根据规则创建相关存储池
```bash
ceph osd pool create cephfs_data 4096 4096 replicated rule-ssd-primary
ceph osd pool create cephfs_metadata 256 256 replicated rule-meta
ceph osd pool create cephfs_tier 256 256 replicated rule-tier
```

+ 配置pool副本集
```bash
ceph osd pool set cephfs_tier size 2
```

+ 添加规则
```
# 获取集群crushmap
$ ceph osd getcrushmap -o crush.bin
# 反编译crushmap
$ crushtool -d crush.bin -o crush.txt
# 编辑crushmap
rule rule-ssd-primary {
        id 3
        type replicated
        min_size 1
        max_size 10
        step take root-tier
        step chooseleaf firstn 1 type host
        step emit
        step take root-data
        step chooseleaf firstn -1 type host
        step emit
}
# 编译crushmap
$ crushtool -c crush.txt -o crush.tal.bin
# 注入crushmap
$ ceph osd setcrushmap -i crush.tal.bin
```

+ 创建filesystem
```
ceph fs new cephfs cephfs_metadata cephfs_data
ceph fs ls
```

+ 挂载
```
mount -t ceph 10.19.250.44:6789:/ /fstal -o name=admin,secret=AQDMztddk0WcEBAAATlaVZSueCEfHTBhueS9Kg==
mount -t ceph 10.19.250.136:6789:/ /mnt/fsailab -o name=admin,secret=AQAXVI9bhEB2ARAAy2VXq0JEdqpkkdcskFI9cA==
```

#### 同一台服务器配置2个mds
```bash
ln -s /lib/systemd/system/ceph-mds@.service ceph-mds@ceph-tal-tier2-work1.service
ln -s /lib/systemd/system/ceph-mds@.service ceph-mds@ceph-tal-tier2-work2.service
mkdir -p /var/lib/ceph/mds/ceph-ceph-tal-tier1-work1
mkdir -p /var/lib/ceph/mds/ceph-ceph-tal-tier1-work2
ceph auth get-or-create mds.ceph-tal-tier1-work2 mon 'allow rwx' osd 'allow *' mds 'allow' -o /var/lib/ceph/mds/ceph-ceph-tal-tier1-work2/keyring    
```

## 添加虚拟OSD
```
mkdir -p /var/lib/ceph/osd/ceph-15/
ceph auth add osd.15 osd  'allow *' mon 'allow rwx' -o /var/lib/ceph/osd/ceph-15/keyring
ceph osd crush add 15 0.000 host=host-virtual-place
```

#### 增加max_mds
&nbsp;&nbsp;&nbsp;&nbsp;每个cephfs文件系统都有一个max_mds设置，可以理解为它将控制创建多少个主MDS。注意只有当实际的MDS个数大于或等于max_mds设置的值时，mdx_mds设置才会生效。例如，如果只有一个MDS守护进程在运行，并且max_mds被设置为两个，则不会创建第二个主MDS
将max_mds设置为所需的个数：
```
ceph fs set cephfs max_mds 2
```
#### 配置备用MDS
&nbsp;&nbsp;&nbsp;&nbsp;即使有多个活动的MDS，如果其中一个MDS出现故障，仍然需要备用守护进程来接管。因此，对于高可用性系统，实际配置max_mds时，最好比系统中MDS的总数少一个。
```
ceph fs set <fs> standby_count_wanted 0 
```

#### 定时清理过期inode
```
$ ceph daemon mds.ceph-tal-osd1 perf dump mds
{
    ...
    "inodes_expired": 94788920,
    ...
}

$ sudo vim /etc/ceph/ceph.conf
……
[client]
client_try_dentry_invalidate = false

systemctl restart ceph-mds@ceph-tal-tier1-work1.service
```


#### 查看目录是否存在脏数据
```
root@ceph-tal-osd1:~# ceph daemon mds.ceph-tal-osd1-work1 dirfrag ls /
[
    {
        "value": 0,
        "bits": 0,
        "str": "0/0"
    }
]
```

#### 查看是否cache
```
root@ceph-tal-osd1:~# ceph daemon mds.ceph-tal-osd1-work1 cache status
{
    "pool": {
        "items": 141060008,
        "bytes": 13215568069
    }
}
```

#### 定位对象
```
rados put {object-name} {file-path} --pool=mytest
rados -p mytest ls
ceph osd map mytest test-object-1
rados purge cephfs_tier --yes-i-really-really-mean-it
```

#### share绑定到SSD
```
ceph fs add_data_pool cephfs cephfs_tier
```
+ 获取文件夹布局
```
授权：
ceph auth get-or-create client.admin mon 'allow *' mds 'allow rwx, allow rwx path=/mnt/fstal/tal-volumes/axer-prod/sysbench/volume-shared-ssd' osd 'allow rwx pool=cephfs_tier'

ceph auth get-or-create client.admin mon 'allow *' mds 'allow *' osd 'allow *' mgr 'allow *'
ceph auth get-or-create mds.ceph-tal-tier1-work2 mon 'allow rwx' osd 'allow *' mds 'allow' -o /var/lib/ceph/mds/ceph-ceph-tal-tier1-work2/keyring    
```

#### ceph_exporter
ceph_exporter。基本原理是利用 librados，从 ceph monitor 中取数据，通过 http 协议把指标以 prometheus 规定的格式暴露出来。
+ 是个纯采集组件，只需部署一处，和 ceph monitor 通信，模式简单易理解，非常看好。
+ 一个缺点是 prometheus 系统本身具有的。其插件是通过 exporter 的形式分散到各个仓库里，分别部署，那么多 exporter，每个都是独立的进程，怎么管理它们是个大问题。管理就包括部署，监控，升级，配置管理，启动和停止，每一个都是问题。相比之下，collectd 做为一个采集框架，为所有插件的实现提供了共有基础功能，使得插件的实现变得非常简单：
+ 为插件提供了运行环境。插件只需提供 read （input 插件），write（output 插件），无需启动进程，无需处理信号。
+ 为插件提供了配置系统。插件无需担心如何如何配置自己，用户只要在 collectd 配置文件中按统一格式传入，插件就可以以统一的方式拿到。
+ 为插件提供了 Log 机制。插件可以使用 collectd 的日志机制，从而无需担心如何支持 level，输出到不同地方等。
+ 为插件提供了数据通道。插件之间的数据是打通的，插件无需关心输出到哪，是 graphite，influxdb，还是 opentsdb。只需实现 read 回调来采集数据，然后配置不同的 output 插件，就能实现输出到不同地方。
